{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Evaluation\n",
    "#### Load the book targeting data\n",
    "Note: these data are from a marketing campaign by a website that sells books. This website experimented with different promotions to try to learn which promotions work best for which customers.\n",
    "#### Develop a model to predict whether the customer bought the promoted book (“promotedbook” == 1)\n",
    "    Inspect the data, especially the distribution of the outcome variable\n",
    "    Deal with missing records\n",
    "    Scale the features\n",
    "    Compare the following metrics: accuracy, recall, and precision. Why do these differ? (Tip: examine the confusion matrix)\n",
    "    Find the model that produces the best F score (tip: set “scoring” attribute in cross-validation or grid search functions to “f1”)\n",
    "#### Analyze the ROC and Profit curves\n",
    "    Include a baseline model to compare with your best model\n",
    "    For the Profit curve, pick your own cost-benefit matrix and in a note, briefly justify your choices\n",
    "    Identify the ideal probability threshold, and interpret how your best model performs in comparison to the baseline model\n",
    "#### Variable definitions:\n",
    "    message_loss = promotional message emphasized lost opportunity if reader did not buy the book\n",
    "    message_gain = promotional message emphasized gains if reader did buy the book\n",
    "    romance_reader / fantasy_reader / realistic_reader = % of reader's prior books in each of these genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# organizing tests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# some metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import plot_tree\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#new modules\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are a lot of other metrics!\n",
    "import sklearn.metrics\n",
    "# dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17626, 12)\n",
      "12 columns: ['promotedbook', 'message_loss', 'message_gain', 'prior_paymenttraj', 'priorpageview', 'loginpriorlogin', 'priorspending', 'priorbooks', 'date', 'romance_reader', 'fantasy_reader', 'realistic_reader']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promotedbook</th>\n",
       "      <th>message_loss</th>\n",
       "      <th>message_gain</th>\n",
       "      <th>prior_paymenttraj</th>\n",
       "      <th>priorpageview</th>\n",
       "      <th>loginpriorlogin</th>\n",
       "      <th>priorspending</th>\n",
       "      <th>priorbooks</th>\n",
       "      <th>date</th>\n",
       "      <th>romance_reader</th>\n",
       "      <th>fantasy_reader</th>\n",
       "      <th>realistic_reader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3664.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13140.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>14203.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   promotedbook  message_loss  message_gain  prior_paymenttraj  priorpageview  \\\n",
       "0           0.0           0.0           1.0                2.0         3664.0   \n",
       "1           0.0           0.0           0.0                3.0         1425.0   \n",
       "2           0.0           1.0           0.0                1.0            5.0   \n",
       "3           0.0           0.0           0.0                3.0         1817.0   \n",
       "4           0.0           0.0           0.0                1.0          171.0   \n",
       "\n",
       "   loginpriorlogin  priorspending  priorbooks  date  romance_reader  \\\n",
       "0            128.0          366.0        68.0    31        0.088235   \n",
       "1             49.0        13140.0         7.0    28        0.857143   \n",
       "2              3.0            0.0         1.0     2        1.000000   \n",
       "3             69.0        14203.0        36.0    23        0.181818   \n",
       "4             10.0            0.0         4.0     8        0.250000   \n",
       "\n",
       "   fantasy_reader  realistic_reader  \n",
       "0        0.897059          0.014706  \n",
       "1        0.142857          0.000000  \n",
       "2        0.000000          0.000000  \n",
       "3        0.727273          0.090909  \n",
       "4        0.000000          0.750000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the book targeting dataPreview the document\n",
    "df = pd.read_csv('book_targeting.csv')\n",
    "print(df.shape)\n",
    "cols = df.columns.to_list()\n",
    "print(len(cols), 'columns:', cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix missing records\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promotedbook</th>\n",
       "      <th>message_loss</th>\n",
       "      <th>message_gain</th>\n",
       "      <th>prior_paymenttraj</th>\n",
       "      <th>priorpageview</th>\n",
       "      <th>loginpriorlogin</th>\n",
       "      <th>priorspending</th>\n",
       "      <th>priorbooks</th>\n",
       "      <th>date</th>\n",
       "      <th>romance_reader</th>\n",
       "      <th>fantasy_reader</th>\n",
       "      <th>realistic_reader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "      <td>17626.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.338023</td>\n",
       "      <td>0.332861</td>\n",
       "      <td>2.105923</td>\n",
       "      <td>1166.083797</td>\n",
       "      <td>56.412856</td>\n",
       "      <td>5297.370419</td>\n",
       "      <td>22.679621</td>\n",
       "      <td>19.321854</td>\n",
       "      <td>0.283991</td>\n",
       "      <td>0.522770</td>\n",
       "      <td>0.165836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.172799</td>\n",
       "      <td>0.473050</td>\n",
       "      <td>0.471250</td>\n",
       "      <td>0.868201</td>\n",
       "      <td>1104.773917</td>\n",
       "      <td>63.718220</td>\n",
       "      <td>5364.604939</td>\n",
       "      <td>41.583065</td>\n",
       "      <td>11.636541</td>\n",
       "      <td>0.323688</td>\n",
       "      <td>0.372697</td>\n",
       "      <td>0.278745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>934.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.548703</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1786.750000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>8530.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5194.000000</td>\n",
       "      <td>852.000000</td>\n",
       "      <td>46960.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       promotedbook  message_loss  message_gain  prior_paymenttraj  \\\n",
       "count  17626.000000  17626.000000  17626.000000       17626.000000   \n",
       "mean       0.030807      0.338023      0.332861           2.105923   \n",
       "std        0.172799      0.473050      0.471250           0.868201   \n",
       "min        0.000000      0.000000      0.000000           1.000000   \n",
       "25%        0.000000      0.000000      0.000000           1.000000   \n",
       "50%        0.000000      0.000000      0.000000           2.000000   \n",
       "75%        0.000000      1.000000      1.000000           3.000000   \n",
       "max        1.000000      1.000000      1.000000           3.000000   \n",
       "\n",
       "       priorpageview  loginpriorlogin  priorspending    priorbooks  \\\n",
       "count   17626.000000     17626.000000   17626.000000  17626.000000   \n",
       "mean     1166.083797        56.412856    5297.370419     22.679621   \n",
       "std      1104.773917        63.718220    5364.604939     41.583065   \n",
       "min         0.000000         0.000000       0.000000      0.000000   \n",
       "25%       144.000000         9.000000       0.000000      3.000000   \n",
       "50%       934.000000        43.000000    3974.000000      9.000000   \n",
       "75%      1786.750000        73.000000    8530.000000     22.000000   \n",
       "max      5194.000000       852.000000   46960.000000    480.000000   \n",
       "\n",
       "               date  romance_reader  fantasy_reader  realistic_reader  \n",
       "count  17626.000000    17626.000000    17626.000000      17626.000000  \n",
       "mean      19.321854        0.283991        0.522770          0.165836  \n",
       "std       11.636541        0.323688        0.372697          0.278745  \n",
       "min        0.000000        0.000000        0.000000          0.000000  \n",
       "25%        6.000000        0.000000        0.153846          0.000000  \n",
       "50%       25.000000        0.142857        0.548703          0.028571  \n",
       "75%       30.000000        0.500000        0.888889          0.200000  \n",
       "max       31.000000        1.000000        1.000000          1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop a model to predict whether the customer bought the promoted book "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    17083\n",
      "1.0      543\n",
      "Name: promotedbook, dtype: int64 \n",
      "\n",
      "proportion in positive class: 0.031\n",
      "baseline accuracy: 0.969\n"
     ]
    }
   ],
   "source": [
    "# Inspect the data, especially the distribution of the outcome variable\n",
    "\n",
    "print(df.promotedbook.value_counts(), '\\n')\n",
    "posrt = (df.promotedbook.sum()/len(df.index)).round(3)\n",
    "print('proportion in positive class:', posrt)\n",
    "print('baseline accuracy:', 1-posrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = df.promotedbook.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['message_loss', 'message_gain', 'prior_paymenttraj', 'priorpageview', 'loginpriorlogin', 'priorspending', 'priorbooks', 'date', 'romance_reader', 'fantasy_reader', 'realistic_reader'] \n",
      "\n",
      "training data: (14100, 11)\n",
      "test data: (3526, 11)\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "# put all the predictive features in a list\n",
    "xcols = df.columns[1 : len(df.columns)].to_list()\n",
    "print(xcols,'\\n')\n",
    "\n",
    "# split the data into training (80%) and testing (20%) portions\n",
    "# notes: train_test_split shuffles the data prior to splitting, so should be randomized\n",
    "# the 'random_state' feature ensures that you get the same split of the data every time\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[xcols], df['promotedbook'], \n",
    "                                                    train_size=0.8, random_state=1)\n",
    "print('training data:', X_train.shape)\n",
    "print('test data:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1: Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9678\n",
      "test accuracy: 0.9728\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "# initialize the logistic regression model\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# fit the model to the training data\n",
    "log_clf = log_reg.fit(X_train, y_train)\n",
    "# get accuracy stats\n",
    "print('training accuracy: {}'.format(log_clf.score(X_train, y_train).round(4)))\n",
    "print('test accuracy: {}'.format(log_clf.score(X_test, y_test).round(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten largest positive features:\n",
      "               feature  coefficient\n",
      "7                date     0.098057\n",
      "6          priorbooks     0.011146\n",
      "5       priorspending     0.000017\n",
      "3       priorpageview    -0.000192\n",
      "4     loginpriorlogin    -0.002155\n",
      "0        message_loss    -0.015024\n",
      "2   prior_paymenttraj    -0.246265\n",
      "1        message_gain    -0.722173\n",
      "8      romance_reader    -0.894885\n",
      "10   realistic_reader    -1.054247 \n",
      "\n",
      "Ten largest negative features:\n",
      "               feature  coefficient\n",
      "6          priorbooks     0.011146\n",
      "5       priorspending     0.000017\n",
      "3       priorpageview    -0.000192\n",
      "4     loginpriorlogin    -0.002155\n",
      "0        message_loss    -0.015024\n",
      "2   prior_paymenttraj    -0.246265\n",
      "1        message_gain    -0.722173\n",
      "8      romance_reader    -0.894885\n",
      "10   realistic_reader    -1.054247\n",
      "9      fantasy_reader    -1.383554\n"
     ]
    }
   ],
   "source": [
    "# put the coefficients into a new dataframe\n",
    "coef = pd.concat([pd.DataFrame(xcols),pd.DataFrame(np.transpose(log_clf.coef_))], axis = 1)\n",
    "coef.columns = ['feature','coefficient']\n",
    "coef.sort_values(by=['coefficient'], ascending=False, inplace=True)\n",
    "# examine the features with the largest coefficients\n",
    "print('Ten largest positive features:\\n', coef.head(10), '\\n')\n",
    "print('Ten largest negative features:\\n', coef.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax scaler normalizes data to range from 0-1\n",
    "#  subtracts each value from the feature's minimum and then divides by the feature's range\n",
    "#  then scales \n",
    "# initialize the scaler function\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "# note: it is important to do this separately for training and testing data\n",
    "#  in order to prevent data leakage, whereby training data contains info about test data\n",
    "scaled_train = scaler.fit_transform(X_train)\n",
    "scaled_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9682\n",
      "test accuracy: 0.9731\n",
      "Ten largest positive features:\n",
      "            feature  coefficient\n",
      "6       priorbooks     2.906867\n",
      "7             date     2.783276\n",
      "4  loginpriorlogin     0.772447\n",
      "5    priorspending     0.329795\n",
      "0     message_loss     0.273361 \n",
      "\n",
      "Ten largest negative features:\n",
      "               feature  coefficient\n",
      "10   realistic_reader    -0.112374\n",
      "2   prior_paymenttraj    -0.299072\n",
      "8      romance_reader    -0.303899\n",
      "9      fantasy_reader    -0.327120\n",
      "3       priorpageview    -0.685463\n"
     ]
    }
   ],
   "source": [
    "##### redo the logistic regression w/ normalized data\n",
    "log_clf = log_reg.fit(scaled_train, y_train)\n",
    "print('training accuracy: {}'.format(log_clf.score(scaled_train, y_train).round(4)))\n",
    "print('test accuracy: {}'.format(log_clf.score(scaled_test, y_test).round(4)))\n",
    "\n",
    "# re-examine coefficients\n",
    "coef = pd.concat([pd.DataFrame(xcols),pd.DataFrame(np.transpose(log_clf.coef_))], axis = 1)\n",
    "coef.columns = ['feature','coefficient']\n",
    "coef.sort_values(by=['coefficient'], ascending=False, inplace=True)\n",
    "print('Ten largest positive features:\\n', coef.head(5), '\\n')\n",
    "print('Ten largest negative features:\\n', coef.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['priorbooks', 'date', 'loginpriorlogin', 'priorspending', 'message_loss', 'realistic_reader', 'prior_paymenttraj', 'romance_reader', 'fantasy_reader', 'priorpageview']\n"
     ]
    }
   ],
   "source": [
    "xcols2 = coef.feature[0:5].to_list()\n",
    "xcols2 += coef.feature[-5:].to_list()\n",
    "print(xcols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001\n",
      "[0.96880318 0.9693617  0.9693617  0.96765957 0.96851064]\n",
      "Accuracy: 0.969 (+/- 0.001) \n",
      "\n",
      "C = 0.01\n",
      "[0.96880318 0.9693617  0.9693617  0.96765957 0.96851064]\n",
      "Accuracy: 0.969 (+/- 0.001) \n",
      "\n",
      "C = 0.1\n",
      "[0.96880318 0.9693617  0.9693617  0.96765957 0.96851064]\n",
      "Accuracy: 0.969 (+/- 0.001) \n",
      "\n",
      "C = 1\n",
      "[0.96880318 0.9693617  0.9693617  0.96765957 0.96851064]\n",
      "Accuracy: 0.969 (+/- 0.001) \n",
      "\n",
      "C = 10\n",
      "[0.96880318 0.9693617  0.9693617  0.96765957 0.96851064]\n",
      "Accuracy: 0.969 (+/- 0.001) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross-validation w/ tuning regularization in logistic regression\n",
    "cset = [.001, .01, .1, 1, 10]\n",
    "for i in cset:\n",
    "    print('C =', i)\n",
    "    log_clf = LogisticRegression(solver='lbfgs', max_iter=1000, C=i)\n",
    "    scores = cross_val_score(log_reg, df[xcols2], df['promotedbook'], cv=5)\n",
    "    print(scores)\n",
    "    print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2: SVM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon, 08 Mar 2021 02:08:56\n",
      "training accuracy: 0.96\n",
      "test accuracy: 0.964\n",
      "Mon, 08 Mar 2021 02:17:44\n"
     ]
    }
   ],
   "source": [
    "# support vector machine w/o normalized data\n",
    "print(time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime()))\n",
    "svm = SVC(kernel = 'linear')\n",
    "#fit the model to the training data\n",
    "svm_clf = svm.fit(X_train, y_train)\n",
    "# get accuracy stats\n",
    "print('training accuracy: {}'.format(svm_clf.score(X_train, y_train).round(3)))\n",
    "print('test accuracy: {}'.format(svm_clf.score(X_test, y_test).round(3)))\n",
    "print(time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon, 08 Mar 2021 02:21:03\n",
      "training accuracy: 0.968\n",
      "test accuracy: 0.973\n",
      "Mon, 08 Mar 2021 02:21:04\n"
     ]
    }
   ],
   "source": [
    "# support vector machine w/ normalized data\n",
    "print(time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime()))\n",
    "svm_clf = svm.fit(scaled_train, y_train)\n",
    "print('training accuracy: {}'.format(svm_clf.score(scaled_train, y_train).round(3)))\n",
    "print('test accuracy: {}'.format(svm_clf.score(scaled_test, y_test).round(3)))\n",
    "print(time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten largest positive features:\n",
      "              feature  coefficient\n",
      "4    loginpriorlogin     0.000680\n",
      "7               date     0.000155\n",
      "2  prior_paymenttraj     0.000098\n",
      "8     romance_reader     0.000081\n",
      "3      priorpageview     0.000050 \n",
      "\n",
      "Ten largest negative features:\n",
      "              feature  coefficient\n",
      "5      priorspending    -0.000024\n",
      "9     fantasy_reader    -0.000025\n",
      "10  realistic_reader    -0.000054\n",
      "0       message_loss    -0.000067\n",
      "6         priorbooks    -0.000591\n"
     ]
    }
   ],
   "source": [
    "# examine coefficients for SVM Model\n",
    "coef = pd.concat([pd.DataFrame(xcols),pd.DataFrame(np.transpose(svm_clf.coef_))], axis = 1)\n",
    "coef.columns = ['feature','coefficient']\n",
    "coef.sort_values(by=['coefficient'], ascending=False, inplace=True)\n",
    "print('Ten largest positive features:\\n', coef.head(5), '\\n')\n",
    "print('Ten largest negative features:\\n', coef.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001\n",
      "training accuracy: 0.968\n",
      "test accuracy: 0.973 \n",
      "\n",
      "C = 0.01\n",
      "training accuracy: 0.968\n",
      "test accuracy: 0.973 \n",
      "\n",
      "C = 0.1\n",
      "training accuracy: 0.968\n",
      "test accuracy: 0.973 \n",
      "\n",
      "C = 1\n",
      "training accuracy: 0.968\n",
      "test accuracy: 0.973 \n",
      "\n",
      "C = 10\n",
      "training accuracy: 0.968\n",
      "test accuracy: 0.973 \n",
      "\n",
      "C = 100\n",
      "training accuracy: 0.968\n",
      "test accuracy: 0.973 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normalization + regularization w/ the C parameter (note: default C = 1)\n",
    "cset = [.001, .01, .1, 1, 10, 100]\n",
    "for i in cset:\n",
    "    print('C =', i)\n",
    "    svm = SVC(kernel = 'linear', C = i)\n",
    "    svm_clf = svm.fit(scaled_train, y_train)\n",
    "    print('training accuracy: {}'.format(svm_clf.score(scaled_train, y_train).round(3)))\n",
    "    print('test accuracy: {}'.format(svm_clf.score(scaled_test, y_test).round(3)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['priorbooks', 'date', 'loginpriorlogin', 'priorspending', 'message_loss', 'realistic_reader', 'prior_paymenttraj', 'romance_reader', 'fantasy_reader', 'priorpageview']\n"
     ]
    }
   ],
   "source": [
    "xcols2 = coef.feature[0:5].to_list()\n",
    "xcols2 += coef.feature[-5:].to_list()\n",
    "print(xcols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001\n",
      "[0. 0. 0. 0. 0.]\n",
      "Accuracy: 0.00 (+/- 0.00)\n",
      "C = 0.01\n"
     ]
    }
   ],
   "source": [
    "# cross-validation w/ tuning regularization in SVM\n",
    "cset = [.001, .01, .1, 1, 10]\n",
    "for i in cset:\n",
    "    print('C =', i)\n",
    "    svm = SVC(kernel = 'linear', C = i)\n",
    "    scores = cross_val_score(svm, df[xcols2], df['promotedbook'], cv=5, scoring = 'f1')\n",
    "    print(scores)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing evaluations\n",
    "Compare the following metrics: accuracy, recall, and precision. Why do these differ? (Tip: examine the confusion matrix).\n",
    "\n",
    "Find the model that produces the best F score (tip: set “scoring” attribute in cross-validation or grid search functions to “f1”)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recall: 0.011\n",
      "  Precision: 0.500\n",
      "  F1 score: 0.021\n",
      "  Specificity: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Chosing the Log Reg model after cross validation\n",
    "\n",
    "# let's check out some other stats for the test data\n",
    "# note: we first get the predicted values and then pass these to each metric w/ the actual values\n",
    "\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000, C=.1)\n",
    "log_clf = log_reg.fit(df[xcols], df['promotedbook'])\n",
    "\n",
    "y_pred_testlog = log_clf.predict(X_test)\n",
    "print('  Recall: {:.3f}'.format(recall_score(y_test, y_pred_testlog)))\n",
    "print('  Precision: {:.3f}'.format(precision_score(y_test, y_pred_testlog)))\n",
    "print('  F1 score: {:.3f}'.format(f1_score(y_test, y_pred_testlog)))\n",
    "cm = confusion_matrix(y_test, y_pred_testlog)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print('  Specificity: {:.3f}'.format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM key:\n",
      " [['TN' 'FP']\n",
      " ['FN' 'TP']] \n",
      "\n",
      "CM for test:\n",
      " [[3431    1]\n",
      " [  93    1]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_testlog)\n",
    "sample = np.array([['TN', 'FP'], ['FN', 'TP']])\n",
    "print('CM key:\\n', sample, '\\n')\n",
    "print('CM for test:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recall: 0.000\n",
      "  Precision: 0.000\n",
      "  F1 score: 0.000\n",
      "  Specificity: 0.998\n"
     ]
    }
   ],
   "source": [
    "# Chosing the SVM model after cross validation\n",
    "\n",
    "svm = SVC(kernel = 'linear', C = .1, probability=True)\n",
    "svm_clf = svm.fit(df[xcols], df['promotedbook'])\n",
    "\n",
    "y_pred_testsvm = svm_clf.predict(X_test)\n",
    "print('  Recall: {:.3f}'.format(recall_score(y_test, y_pred_testsvm)))\n",
    "print('  Precision: {:.3f}'.format(precision_score(y_test, y_pred_testsvm)))\n",
    "print('  F1 score: {:.3f}'.format(f1_score(y_test, y_pred_testsvm)))\n",
    "cm = confusion_matrix(y_test, y_pred_testsvm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print('  Specificity: {:.3f}'.format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_testsvm)\n",
    "sample = np.array([['TN', 'FP'], ['FN', 'TP']])\n",
    "print('CM key:\\n', sample, '\\n')\n",
    "print('CM for test:\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy, recall, and precision differ for Model1 (Log) and Model2 (SVM) because the number of true negatives & postives , false negatives & positives are different in both models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model using SVM has the best F1 score of .075 , C = 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remedying class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify algorithm approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the algorithm's objective w/ class_weight attribute\n",
    "svm = SVC(kernel = 'linear', C = 0.1)\n",
    "clf = svm.fit(X_train, y_train)\n",
    "print('training accuracy: {}'.format(clf.score(X_train, y_train).round(4)))\n",
    "print('test accuracy: {}'.format(clf.score(X_test, y_test).round(4)))\n",
    "print('other test stats:')\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print('  Recall: {:.3f}'.format(recall_score(y_test, y_pred_test)))\n",
    "print('  Precision: {:.3f}'.format(precision_score(y_test, y_pred_test)))\n",
    "print('  F1 score: {:.3f}'.format(f1_score(y_test, y_pred_test)))\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print('  Specificity: {:.3f}'.format(specificity))\n",
    "print('confusion matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify sample approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run this code to install package for ML w/ imbalanced data\n",
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random oversampling: randomly add cases from the minority (sampling w/ replacement) to achieve desired balance\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# setup data and examine distribution of outcome\n",
    "X, y = df[xcols], df['promotedbook']\n",
    "print(y.value_counts())\n",
    "\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "#oversample = RandomOverSampler(sampling_strategy=0.5) # can also oversample to achieve a ratio < 1:1 \n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "\n",
    "# new class distribution\n",
    "print(y_over.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine results\n",
    "# note: new variables passed to train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, \n",
    "                                                    random_state=0)\n",
    "print('train shape:', X_train.shape)\n",
    "print('test shape:', X_test.shape, '\\n')\n",
    "\n",
    "svm = SVC(kernel = 'linear', C = 0.1)\n",
    "clf = svm.fit(X_train, y_train)\n",
    "print('training accuracy: {}'.format(clf.score(X_train, y_train).round(4)))\n",
    "print('test accuracy: {}'.format(clf.score(X_test, y_test).round(4)))\n",
    "print('other test stats:')\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print('  Recall: {:.3f}'.format(recall_score(y_test, y_pred_test)))\n",
    "print('  Precision: {:.3f}'.format(precision_score(y_test, y_pred_test)))\n",
    "print('  F1 score: {:.3f}'.format(f1_score(y_test, y_pred_test)))\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print('  Specificity: {:.3f}'.format(specificity))\n",
    "print('confusion matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but how well does it do on the original dataset?\n",
    "y_pred = clf.predict(X)\n",
    "print('Accuracy: {:.3f}'.format(clf.score(X, y)))\n",
    "print('Recall: {:.3f}'.format(recall_score(y, y_pred)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y, y_pred)))\n",
    "print('F1 score: {:.3f}'.format(f1_score(y, y_pred)))\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity: {:.3f}'.format(specificity))\n",
    "print('confusion matrix:\\n', cm)\n",
    "# how could this have been done better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple ROC curve for 1 estimator\n",
    "svm = SVC(kernel = 'linear', C = 0.1)\n",
    "clf = svm.fit(X_train, y_train)\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "x = np.linspace(0,1.0)\n",
    "plt.plot(x, x, color='grey',ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "#fit the decision tree and output accuracy constrained by depth\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=6).fit(X, y)\n",
    "print('Accuracy of Decision Tree classifier: {:.2f}'\n",
    "     .format(clf.score(X, y)))\n",
    "\n",
    "r = export_text(clf, feature_names=xcols)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize feature importance, and store values under feature names in scores dictionary\n",
    "importance = clf.feature_importances_\n",
    "scores = {}\n",
    "for i,v in enumerate(importance):\n",
    "    #print('Feature: %s, Score: %.5f' % (xcols[i],v))\n",
    "    scores[xcols[i]] = v\n",
    "\n",
    "#reverse sort 'scores' dictionary by values\n",
    "import operator\n",
    "sorted_scores = sorted(scores.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "#print top 10 features\n",
    "for feature, score in sorted_scores[0:10]:\n",
    "    print(feature, ':', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have chosen \"priorbooks\" as baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full model\n",
    "svm = SVC(kernel = 'linear', C = 0.1)\n",
    "clf = svm.fit(X_train, y_train)\n",
    "lr_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# 1 feature model\n",
    "svm = SVC(kernel = 'linear', C = 0.1)\n",
    "X_train2 = X_train[['priorbooks']]\n",
    "X_test2 = X_test[['priorbooks']]\n",
    "clf2 = log_reg2.fit(X_train2, y_train)\n",
    "lr_probs2 = clf2.predict_proba(X_test2)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "lr_probs2 = lr_probs2[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "lr_auc2 = roc_auc_score(y_test, lr_probs2)\n",
    "# summarize scores\n",
    "print('Full model: ROC AUC=%.3f' % (lr_auc))\n",
    "print('1 feature: ROC AUC=%.3f' % (lr_auc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "# get the false positve rates and true positive rates for each model\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "lr_fpr2, lr_tpr2, _ = roc_curve(y_test, lr_probs2)\n",
    "# plot the roc curves for the model\n",
    "plt.plot(lr_fpr, lr_tpr, linestyle='--', label='Full model')\n",
    "plt.plot(lr_fpr2, lr_tpr2, marker='.', label='1 feature')\n",
    "# plot title\n",
    "plt.title('ROC Curves')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# add a diagonal line\n",
    "x = np.linspace(0, 1.0)\n",
    "plt.plot(x, x, color='grey', ls='--')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profit curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model probability predictions for positive class\n",
    "# Note: uses models created in prior step and stored under 'clf' and 'clf2'\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "y_proba2 = clf2.predict_proba(X_test2)[:, 1]\n",
    "\n",
    "# Define cost-benefit matrix\n",
    "# format: [[tn, fp], [fn, tp]]\n",
    "# signing a potential allstar costs 8000 duckets, but is worth 12,000\n",
    "costbenefit_mat = [[0, -8000], [0, 4000]]\n",
    "    \n",
    "# Profit curve data\n",
    "profits = [] # one profit value for each T (threshold)\n",
    "# sort probabilities into descending order\n",
    "thresholds = sorted(y_proba, reverse=True)\n",
    "\n",
    "# For each threshold, calculate profit - starting with largest threshold\n",
    "for T in thresholds:\n",
    "    y_pred = (y_proba > T).astype(int)\n",
    "    # Calculate confusion matrix for this probability threshold\n",
    "    #[[tn, fp], [fn, tp]] = confusion_matrix(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    # Calculate total profit for this threshold\n",
    "    profit = sum(sum(confusion_mat * costbenefit_mat)) / len(y_test)\n",
    "    profits.append(profit)\n",
    "\n",
    "# Repeat for 2nd model (should put this into a function instead)\n",
    "profits2 = [] # one profit value for each T (threshold)\n",
    "thresholds2 = sorted(y_proba2, reverse=True)\n",
    "for T in thresholds2:\n",
    "    y_pred2 = (y_proba2 > T).astype(int)\n",
    "    confusion_mat2 = confusion_matrix(y_test, y_pred2)\n",
    "    profit2 = sum(sum(confusion_mat2 * costbenefit_mat)) / len(y_test)\n",
    "    profits2.append(profit2)\n",
    "\n",
    "# Profit curve plot\n",
    "model_name = 'Full model'\n",
    "max_profit = max(profits).round(2)\n",
    "model_name2 = '1 feature'\n",
    "max_profit2 = max(profits2).round(2)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(np.linspace(0, 1, len(y_test)), profits, label = '{}, max profit ${} per user'.format(model_name, max_profit))\n",
    "plt.plot(np.linspace(0, 1, len(y_test)), profits2, label = '{}, max profit ${} per user'.format(model_name2, max_profit2))\n",
    "plt.xlabel('Percentage of test instances (decreasing by score)')\n",
    "plt.ylabel('Profit')\n",
    "plt.title('Profit Curves')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
